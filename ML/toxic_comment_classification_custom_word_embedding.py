# -*- coding: utf-8 -*-
"""Toxic Comment Classification Custom Word Embedding.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qUfcpwVGL3Vg0GNG9RSzE3Zd45fVKA47

# Import the dataset
"""

import pandas as pd
import numpy as np
import tensorflow as tf
from keras.preprocessing.text import Tokenizer
from keras.preprocessing.sequence import pad_sequences
from keras import Sequential
from keras.layers import Dense, Embedding, GlobalMaxPool1D
from keras.losses import BinaryCrossentropy
from keras.metrics import AUC
from keras.optimizers import Adam
from keras.models import model_from_json
from tensorflow.compat.v1.keras.layers import CuDNNLSTM
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score

import re
import gc
import pickle

print("Num GPUs Available: ", len(tf.config.experimental.list_physical_devices('GPU')))
tf.debugging.set_log_device_placement(True)

! pip install kaggle

from google.colab import files
files.upload()

! mkdir ~/.kaggle
! cp kaggle.json ~/.kaggle/

! chmod 600 ~/.kaggle/kaggle.json

! kaggle competitions download -c jigsaw-toxic-comment-classification-challenge

! mkdir dataset

! unzip test.csv.zip -d dataset

! unzip train.csv.zip -d dataset

"""# Data Fetching"""

train = pd.read_csv('dataset/train.csv', dtype={'comment_text':'string'})
train.head()

train = train.drop(columns='id')
train.head()

test = pd.read_csv('dataset/test.csv', dtype={'comment_text':'string'})
ids = test.iloc[:,0]
test = test.drop(columns='id')
test.head()

ids.head()

"""# Data Preprocessing"""

X = train['comment_text'].values
Y = train.iloc[:,1:].values

print(X.shape)

print(Y.shape)
Y

X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.2)

tokenizer = Tokenizer()

tokenizer.fit_on_texts(X_train)

X_train_seq = tokenizer.texts_to_sequences(X_train)
X_test_seq = tokenizer.texts_to_sequences(X_test)

len(X_train_seq)

print(len(tokenizer.word_index))

len(X_test)

X_train_seq = pad_sequences(X_train_seq, maxlen=250)
X_test_seq = pad_sequences(X_test_seq, maxlen=250)

X_test_seq.shape

X_train_seq.shape

"""# Custom Embedding"""

vocab_size = len(tokenizer.word_index) + 1
vocab_size

model = Sequential()

model.add(Embedding(input_dim=vocab_size, output_dim = 300, input_length = 250, trainable = True))

model.add(CuDNNLSTM(units=150,return_sequences=True))

model.add(GlobalMaxPool1D())

model.add(Dense(units = 64, activation='relu'))

model.add(Dense(units = 16, activation='relu'))

model.add(Dense(units = 6, activation='sigmoid'))

model.compile(loss=BinaryCrossentropy(),optimizer=Adam(),metrics=[AUC()])

print(model.summary())

type(X_train_seq)

history = model.fit(np.array(X_train_seq), np.array(y_train), batch_size=128, epochs=10, validation_data=(np.array(X_test_seq),np.array(y_test)))

model_json = model.to_json()

with open('custom_embedding.json', 'w') as json_file:
  json_file.write(model_json)

model.save_weights("weights.h5")

json_file = open('custom_embedding.json', 'r')
loaded_model_json = json_file.read()
json_file.close()
loaded_model = model_from_json(loaded_model_json)

with open('tokenizer.pickle', 'wb') as handle:
    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)

with open('tokenizer.pickle', 'rb') as handle:
    tokenizer = pickle.load(handle)

loaded_model.load_weights("weights.h5")

loaded_model.compile(loss=BinaryCrossentropy(),optimizer=Adam(),metrics=[AUC()])

"""# Kaggle Submission"""

test.head()

test_X = test['comment_text'].values
test_X

test_X_seq = tokenizer.texts_to_sequences(test_X)

test_X_seq = pad_sequences(test_X_seq, maxlen=250)

prediction = loaded_model.predict(test_X_seq)
prediction

prediction.shape

result = pd.DataFrame()
result.head()

result["id"] = ids
result.head()

result["toxic"] = prediction[:,0]
result["severe_toxic"] = prediction[:,1]
result["obscene"] = prediction[:,2]
result["threat"] = prediction[:,3]
result["insult"] = prediction[:,4]
result["identity_hate"] = prediction[:,5]
result.head()

result.to_csv('submission.csv', index=False)

! kaggle competitions submit -c jigsaw-toxic-comment-classification-challenge -f submission.csv -m "Using Custom Word Embeddings"